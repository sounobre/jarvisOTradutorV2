Com certeza, amigo\! Este √© o documento definitivo do seu projeto.

Escrevi este **README.md** pensando em dois p√∫blicos:

1.  **Voc√™ do Futuro:** Para quando precisar reinstalar tudo daqui a 6 meses e n√£o lembrar dos "pulos do gato" (como o `llama-cpp-python` com CUDA).
2.  **Investidores/Parceiros:** Para mostrar a robustez da engenharia de dados que voc√™ construiu.

Pode copiar e salvar na raiz do seu projeto como `README.md`.

-----

# üìö Jarvis V2: AI High-Fantasy Book Translator

> **Uma plataforma de Engenharia de Dados e Tradu√ß√£o Neural Local para Alta Fantasia.**

O **Jarvis V2** √© um pipeline de ponta a ponta para localiza√ß√£o de livros (Ingl√™s -\> Portugu√™s), focado na preserva√ß√£o de estilo liter√°rio e estrutura de formata√ß√£o. O sistema roda 100% localmente (On-Premises) utilizando uma GPU consumer (RTX 3060 12GB), eliminando custos de API e garantindo privacidade total dos dados.

-----

## üöÄ Arquitetura do Sistema

O projeto √© dividido em dois grandes pilares:

### 1\. A "F√°brica de Dados" (Corpus Builder)

Respons√°vel por criar datasets de treinamento ("Fine-Tuning") de alt√≠ssima qualidade a partir de livros j√° traduzidos.

  * **Segmenta√ß√£o Inteligente:** Utiliza **Stanza** (Stanford NLP) para quebrar textos respeitando di√°logos e prosa complexa.
  * **Alinhamento Neural:** Utiliza **SentenceTransformers** (Embeddings) + **SentAlign** (Programa√ß√£o Din√¢mica) para alinhar senten√ßas EN-PT, detectando pares 1-para-1, 1-para-2 e 2-para-1.
  * **Valida√ß√£o Automatizada:** Filtros estat√≠sticos (Length Ratio, Number Matching) para garantir pureza no dataset final.

### 2\. O "Motor de Tradu√ß√£o" (Translation Engine)

Respons√°vel pela tradu√ß√£o produtiva de novos livros.

  * **Preserva√ß√£o de EPUB:** Descompacta a estrutura do livro, isola tags HTML/Imagens usando placeholders (`[TAG_001]`) e reconstr√≥i o arquivo final.
  * **Inje√ß√£o de Gloss√°rio:** Sistema din√¢mico que injeta terminologia obrigat√≥ria (ex: "High Lord" -\> "Gr√£o-Senhor") diretamente no contexto do modelo.
  * **Infer√™ncia Local:** Roda LLMs de 7B/14B par√¢metros (Qwen 2.5, Mistral) quantizados em 4-bit/5-bit via **GGUF** e **CUDA**.

-----

## üõ†Ô∏è Tech Stack

  * **Linguagem:** Python 3.11
  * **API Framework:** FastAPI (Async)
  * **Banco de Dados:** PostgreSQL + AsyncPG + SQLAlchemy 2.0
  * **IA & NLP:**
      * `llama-cpp-python` (Infer√™ncia GGUF com acelera√ß√£o CUDA)
      * `sentence-transformers` (Embeddings Sem√¢nticos)
      * `stanza` (Segmenta√ß√£o SOTA)
      * `scikit-learn` & `numpy` (C√°lculos Matriciais)
  * **Infraestrutura:** Windows 11 + WSL2 (Opcional) + CUDA Toolkit 12.1

-----

## ‚öôÔ∏è Instala√ß√£o e Configura√ß√£o

### Pr√©-requisitos

1.  **NVIDIA GPU** (Recomendado: 12GB VRAM ou mais).
2.  **Drivers NVIDIA** atualizados.
3.  **CUDA Toolkit 12.1** instalado no Windows.
4.  **Python 3.11**.

### Instala√ß√£o do Ambiente (.venv)

A ordem de instala√ß√£o √© cr√≠tica para evitar conflitos de driver no Windows.

```bash
# 1. Crie e ative o ambiente
python -m venv .venv
.\.venv\Scripts\activate

# 2. Instale o PyTorch (Vers√£o Est√°vel com CUDA 12.1)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# 3. Instale o Motor de Infer√™ncia (A "Bala de Prata" para Windows)
# Nota: Use --no-cache-dir para for√ßar a vers√£o correta com acelera√ß√£o de GPU
pip install llama-cpp-python --force-reinstall --upgrade --no-cache-dir --index-url https://abetlen.github.io/llama-cpp-python/whl/cu121

# 4. Instale o Restante das Depend√™ncias
pip install fastapi uvicorn sqlalchemy asyncpg pandas openpyxl stanza sentence-transformers scikit-learn python-multipart
```

-----

## üïπÔ∏è Guia de Uso (Painel de Controle)

O sistema √© controlado via API REST (documentada via Swagger/OpenAPI).

### Fluxo A: Criar Corpus (Treinamento)

Este fluxo transforma um par de EPUBs (Original + Tradu√ß√£o Oficial) em um arquivo `.tsv` para treinar a IA.

1.  **Importar Livros:**

      * `POST /epub/import`: Envie os dois arquivos `.epub` (EN e PT).
      * *Resultado:* Cria os registros no banco. Retorna `import_id`.

2.  **Fase 1: Mapeamento Macro (Agendamento)**

      * `POST /epub/corpus_v2/1-schedule-macro-map`
      * *O que faz:* Compara o conte√∫do dos cap√≠tulos para saber que "Chapter 1" √© par de "CAP√çTULO 1".

3.  **Fase 2: Alinhamento Fino (SentAlign)**

      * `POST /epub/corpus_v2/2c-align-all-pending`
      * *O que faz:* Processa o livro inteiro. Usa **Stanza** para quebrar o texto e **SentAlign** para parear as frases. Roda na GPU.
      * *Monitoramento:* Use `GET /epub/corpus_v2/get-status` para ver o progresso.

4.  **Fase 3: Valida√ß√£o de Qualidade**

      * `POST /epub/corpus_v2/3-validate-corpus`
      * *O que faz:* Aplica m√©tricas (Length Ratio, Number Mismatch) para marcar pares suspeitos.

5.  **Fase 4: Exporta√ß√£o Premium**

      * `POST /epub/corpus_v2/4-export-corpus`
      * *O que faz:* Gera o arquivo final `corpus_premium.tsv` contendo apenas os pares validados e de alta qualidade.

-----

### Fluxo B: Traduzir Livro (Produ√ß√£o)

Este fluxo traduz um livro in√©dito usando o modelo local.

1.  **Importar Livro:**

      * `POST /epub/import-single`: Envie apenas o `.epub` em Ingl√™s.

2.  **Configurar Gloss√°rio (Opcional):**

      * `POST /epub/glossary/add-terms`: Envie JSON com termos fixos (ex: `{"High Lord": "Gr√£o-Senhor"}`).

3.  **Traduzir:**

      * `POST /epub/translate/translate-book`
      * Payload: `{"import_id": 123}`.
      * *O que acontece:*
          * O sistema carrega o modelo **Qwen 2.5 7B Instruct (GGUF)** na VRAM.
          * L√™ o EPUB original e protege tags HTML.
          * Fatia o texto (Chunking Inteligente) e traduz usando Prompt de Sistema especializado.
          * Reconstr√≥i o arquivo `.epub` traduzido na pasta `data/translated/`.

-----

## üìä Estrutura do Banco de Dados

  * `tm_import`: Metadados dos arquivos.
  * `tm_chapter_index`: √çndice estrutural dos cap√≠tulos (HREF, T√≠tulo).
  * `tm_chapter_text`: Conte√∫do bruto dos cap√≠tulos.
  * `tm_win_mapping`: O mapa de relacionamento entre cap√≠tulos (EN \<-\> PT).
  * `tm_aligned_sentences`: O produto final (Pares de senten√ßas com score de similaridade).
  * `tm_translation_log`: Telemetria completa de cada tradu√ß√£o realizada (Prompt usado, Tempo, Temperatura).
  * `tm_glossary`: Dicion√°rio de termos for√ßados por livro.

-----

## üêõ Troubleshooting Comum

**Erro:** `WinError 2: O sistema n√£o pode encontrar o arquivo especificado`

  * **Causa:** Caminho do Python do `SentAlign` incorreto.
  * **Solu√ß√£o:** Verifique a constante `SENTALIGN_PYTHON_PATH` em `services/corpus_builder_service.py`.

**Erro:** `.to is not supported for 4-bit models`

  * **Causa:** Conflito entre `accelerate` e `bitsandbytes` ao mover tensores.
  * **Solu√ß√£o:** Estamos usando `llama-cpp-python` (GGUF), que n√£o sofre desse problema. Certifique-se de ter removido o c√≥digo antigo que usava `AutoModelForCausalLM` do transformers puro.

**Erro:** GPU Usage 0% / CPU 100%

  * **Causa:** `llama-cpp-python` instalado sem suporte a CUDA.
  * **Solu√ß√£o:** Reinstale usando a flag `--force-reinstall --no-cache-dir` e a URL do reposit√≥rio `abetlen` com `cu121`.

-----

> **Jarvis V2** - *Construindo a ponte entre mundos, uma senten√ßa de cada vez.*